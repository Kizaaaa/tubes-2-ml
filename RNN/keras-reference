import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ["KERAS_BACKEND"] = "tensorflow"

import keras
from keras.api.layers import Embedding, SimpleRNN, Bidirectional, Dropout, Dense, TextVectorization
from keras.api.models import Sequential
import pandas as pd
from sklearn.metrics import classification_report, f1_score
from sklearn.preprocessing import LabelEncoder

data = pd.read_csv("../datasets/NusaX-Sentiment-Indonesian/train.csv")
data_valid = pd.read_csv("../datasets/NusaX-Sentiment-Indonesian/valid.csv")

texts = data['text'].values
labels = data['label'].values

# Konfigurasi TextVectorization
tokenizer = TextVectorization(max_tokens=10000, output_mode="int", output_sequence_length=100)
tokenizer.adapt(texts)  # Pelajari vocabulary dari teks

# TextVectorization pada text
tokenized_texts = tokenizer(texts)

# TODO: variasi model sesuai spek
model = Sequential([
    Embedding(input_dim=10000, output_dim=128),
    SimpleRNN(32),
    Dropout(0.5), 
    Dense(3, activation="softmax")
])

model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

# Konversi label menjadi integer (0, 1, 2)
label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(data['label'].values)
labels_valid = label_encoder.transform(data_valid['label'].values)

texts_valid = data_valid['text'].values

# Tokenizer (TextVectorization)
tokenized_texts_valid = tokenizer(texts_valid)

model.fit(
    tokenized_texts, labels,  # Data latih
    validation_data=(tokenized_texts_valid, labels_valid),  # Data validasi
    epochs=10
)

predictions = model.predict(tokenized_texts_valid)

# Mengambil kelas dengan probabilitas tertinggi
predicted_classes = predictions.argmax(axis=1)

accuracy = f1_score(labels_valid, predicted_classes, average='macro')
print(f"Validation F1_Score: {accuracy:.2f}")

print("Classification Report:")
print(classification_report(labels_valid, predicted_classes, target_names=label_encoder.classes_))